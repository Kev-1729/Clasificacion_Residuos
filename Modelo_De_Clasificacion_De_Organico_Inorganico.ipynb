{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CREACION DE UN MODELO DE CLASIFICACION DE ORGANICO E INORGANICO\n",
        "\n",
        "Este proyecto tiene como objetivo entrenar un modelo de clasificación de imágenes utilizando la arquitectura DenseNet121 y el conjunto de datos de imágenes dividido en diferentes categorías\n",
        "\n",
        "```\n",
        "['organic', 'plastico', 'vidrio', 'metal', 'carton', 'papel']\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Requisitos:**\n",
        "\n",
        "\n",
        "* Python 3.x\n",
        "* TensorFlow 2.x\n",
        "* Numpy\n",
        "* Matplotlib\n",
        "* os\n",
        "* shutil\n",
        "\n",
        "**Estructura de directorios:**\n",
        "\n",
        "\n",
        "```\n",
        "# /imagenes_para_entrenar\n",
        "    /train\n",
        "        /organic\n",
        "        /plastico\n",
        "        /vidrio\n",
        "        /metal\n",
        "        /carton\n",
        "        /papel\n",
        "    /test\n",
        "        /organic\n",
        "        /plastico\n",
        "        /vidrio\n",
        "        /metal\n",
        "        /carton\n",
        "        /papel\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9CBfuT-zcSgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Permitir utilizar Drive en Google Colab**"
      ],
      "metadata": {
        "id": "riZ0P74HcIpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS3uUVB74sr9",
        "outputId": "3e45f173-c454-4213-bc2e-03e5208f3960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "LMp4KA8w40Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ruta donde se encuentran las imagenes**"
      ],
      "metadata": {
        "id": "3cv7xZIbfoCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_dataset = '/content/drive/MyDrive/Waste_Classification_Dataset/waste_dataset'\n",
        "imagenes_organic = os.path.join(ruta_dataset, 'organic')\n",
        "imagenes_plastico = os.path.join(ruta_dataset, 'recyclable', 'Plastico')\n",
        "imagenes_vidrio = os.path.join(ruta_dataset, 'recyclable', 'Vidrio')\n",
        "imagenes_metal = os.path.join(ruta_dataset, 'recyclable', 'Metal')\n",
        "imagenes_carton = os.path.join(ruta_dataset, 'recyclable', 'Carton')\n",
        "imagenes_papel = os.path.join(ruta_dataset, 'recyclable', 'Papel')"
      ],
      "metadata": {
        "id": "oUPDydSI41YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crea los directorios de entrenamiento y prueba**"
      ],
      "metadata": {
        "id": "-pUjppVa5WHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/imagenes_para_entrenar/train'\n",
        "test_data_dir = '/content/drive/MyDrive/imagenes_para_entrenar/test'"
      ],
      "metadata": {
        "id": "-KSGhMz742Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copia las imágenes de las categorías en los directorios de entrenamiento y prueba**"
      ],
      "metadata": {
        "id": "YvwNAwVW5a5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = {\n",
        "    'organic': imagenes_organic,\n",
        "    'plastico': imagenes_plastico,\n",
        "    'vidrio': imagenes_vidrio,\n",
        "    'metal': imagenes_metal,\n",
        "    'carton': imagenes_carton,\n",
        "    'papel': imagenes_papel\n",
        "}"
      ],
      "metadata": {
        "id": "nGH_8M6G48lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creación de directorios de entrenamiento y prueba para clasificación de imágenes por categoría**"
      ],
      "metadata": {
        "id": "ygnlqZldbAEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for categoria, directorio in categorias.items():\n",
        "    imagenes = os.listdir(directorio)\n",
        "    num_imagenes = len(imagenes)\n",
        "    num_imagenes_entrenamiento = int(num_imagenes * 0.8)\n",
        "\n",
        "    # Copiamos las imágenes para entrenamiento\n",
        "    train_categoria_dir = os.path.join(train_data_dir, categoria)\n",
        "    os.makedirs(train_categoria_dir, exist_ok=True)\n",
        "    for imagen in imagenes[:num_imagenes_entrenamiento]:\n",
        "        origen = os.path.join(directorio, imagen)\n",
        "        destino = os.path.join(train_categoria_dir, imagen)\n",
        "        shutil.copyfile(origen, destino)\n",
        "\n",
        "    # Copiamos las imágenes para prueba\n",
        "    test_categoria_dir = os.path.join(test_data_dir, categoria)\n",
        "    os.makedirs(test_categoria_dir, exist_ok=True)\n",
        "    for imagen in imagenes[num_imagenes_entrenamiento:]:\n",
        "        origen = os.path.join(directorio, imagen)\n",
        "        destino = os.path.join(test_categoria_dir, imagen)\n",
        "        shutil.copyfile(origen, destino)"
      ],
      "metadata": {
        "id": "uBDJrme65dcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocesamiento de imágenes utilizando ImageDataGenerator de TensorFlow**"
      ],
      "metadata": {
        "id": "rrorXBXVbPBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "sNxOwd6S6X0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generadores de flujo de datos para entrenamiento y prueba**"
      ],
      "metadata": {
        "id": "B6cLALEAbZMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 6\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    classes=['organic', 'plastico', 'vidrio', 'metal', 'carton', 'papel']\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    classes=['organic', 'plastico', 'vidrio', 'metal', 'carton', 'papel']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXn0hX3X6tnT",
        "outputId": "55ccb9c2-e588-42b2-fc8c-0c35f4233305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19748 images belonging to 6 classes.\n",
            "Found 4942 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definición y entrenamiento del modelo de clasificación**"
      ],
      "metadata": {
        "id": "1xwlTJwPbxUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Definimos la arquitectura del modelo\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Congelamos las capas del modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=8,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.n // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ZH0XP-_FF0",
        "outputId": "0eebe6b3-aa31-41e9-b4cc-a6901650d350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "617/617 [==============================] - 326s 517ms/step - loss: 0.5242 - accuracy: 0.8234 - val_loss: 0.3909 - val_accuracy: 0.8600\n",
            "Epoch 2/8\n",
            "617/617 [==============================] - 316s 512ms/step - loss: 0.3403 - accuracy: 0.8866 - val_loss: 0.3902 - val_accuracy: 0.8634\n",
            "Epoch 3/8\n",
            "617/617 [==============================] - 311s 504ms/step - loss: 0.3092 - accuracy: 0.8937 - val_loss: 0.3615 - val_accuracy: 0.8778\n",
            "Epoch 4/8\n",
            "617/617 [==============================] - 317s 513ms/step - loss: 0.2936 - accuracy: 0.8994 - val_loss: 0.4407 - val_accuracy: 0.8598\n",
            "Epoch 5/8\n",
            "617/617 [==============================] - 313s 507ms/step - loss: 0.2834 - accuracy: 0.9048 - val_loss: 0.3652 - val_accuracy: 0.8778\n",
            "Epoch 6/8\n",
            "617/617 [==============================] - 309s 501ms/step - loss: 0.2752 - accuracy: 0.9058 - val_loss: 0.3774 - val_accuracy: 0.8750\n",
            "Epoch 7/8\n",
            "617/617 [==============================] - 314s 509ms/step - loss: 0.2704 - accuracy: 0.9064 - val_loss: 0.3818 - val_accuracy: 0.8742\n",
            "Epoch 8/8\n",
            "617/617 [==============================] - 322s 522ms/step - loss: 0.2668 - accuracy: 0.9069 - val_loss: 0.3413 - val_accuracy: 0.8864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa974204220>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guardar Modelo**"
      ],
      "metadata": {
        "id": "Q9GvSQ5fb2Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/modelo_Ing_Requisitos.h5')"
      ],
      "metadata": {
        "id": "nO6xCUYNYOWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "modelo_guardado = load_model('/content/drive/MyDrive/modelo_Ing_Requisitos.h5')"
      ],
      "metadata": {
        "id": "BBwZ2dj9Ysbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utilizacion del modelo para identificacion**"
      ],
      "metadata": {
        "id": "KAk2qpGQb7L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LLKroV3VZxuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def classify_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((img_width, img_height))\n",
        "    img_array = np.array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    normalized_img_array = expanded_img_array / 255.0\n",
        "\n",
        "    predictions = model.predict(normalized_img_array)\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "    predicted_class_name = class_labels[predicted_class_index]\n",
        "\n",
        "    return predicted_class_name"
      ],
      "metadata": {
        "id": "sSgBA9yGYwoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen_path = '_metal_d5a14eee.jpg' # <======= Introducir imagen\n",
        "resultado = classify_image(imagen_path)\n",
        "print(\"La imagen pertenece a la categoría de:\", resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbk9j6IFZSl5",
        "outputId": "9f2e79f1-caf1-4675-9e0c-b7c6cc392b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "La imagen pertenece a la categoría de: metal\n"
          ]
        }
      ]
    }
  ]
}